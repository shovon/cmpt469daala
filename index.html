<!doctype html>
<html lang="en">

	<head>
		<meta charset="utf-8">

		<title>reveal.js - The HTML Presentation Framework</title>

		<meta name="description" content="A framework for easily creating beautiful presentations using HTML">
		<meta name="author" content="Hakim El Hattab">

		<meta name="apple-mobile-web-app-capable" content="yes" />
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/black.css" id="theme">

		<!-- Code syntax highlighting -->
		<link rel="stylesheet" href="lib/css/zenburn.css">
		<link rel='stylesheet' href='katex/katex.min.css'>

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>

		<style>
			.translucent-black-background {
				background: rgba(0, 0, 0, 0.5);
				padding: 20px !important;
			}
		</style>

		<!--[if lt IE 9]>
		<script src="lib/js/html5shiv.js"></script>
		<![endif]-->
	</head>

	<body>

		<div class="reveal">

			<!-- Any section element inside of this container is displayed as a slide -->
			<div class="slides">
				<section>
					<h1>Using Daala Intra Frames for Still Picture Coding</h1>
					<p>Get better quality, in fewer bytes</p>
				</section>

				<section>
					<h2>What Is Daala?</h2>
					<p>A video codec created to either match or exceed the quality of current-generation of video codecs, such a VP9 and HEVC. Currently an ongoing effort by Xiph and Mozilla to introduce a royalty-free video codec.</p>
				</section>

				<section>
					<section data-background='./images/white-pixel.png'>
						<div class='fragment translucent-black-background'>
							<h2>Problem: Compressing Images</h2>
							<p>LZW, RLE, ZIP, etc. work great...</p>
							<p><small>(Behind, you're seeing a 512 by 512 pixel image, not just a white background)</small></p>
							<table class='fragment'>
								<tr><th>Image</th><th>Size (bytes)</th></tr>
								<tr><td>BMP</td><td>786554</td></tr>
								<tr><td>PNG</td><td>1529</td></tr>
								<tr><td>JPG</td><td>3598</td></tr>
							</table>
						</div>
					</section>

					<section data-background='./images/lena512color.png'>
						<div class='fragment translucent-black-background'>
							<p>Except not so well for more complex images</p>
							<table>
								<tr><th>Image</th><th>Size (bytes)</th></tr>
								<tr><td>BMP</td><td>786554</td></tr>
								<tr><td>PNG</td><td>476235</td></tr>
								<tr><td>JPG</td><td>408932</td></tr>
							</table>
						</div>
					</section>

					<section data-background='./images/noise.png'>
						<div class='fragment translucent-black-background'>
							<p>Even worse for noise</p>
							<table>
								<tr><th>Image</th><th>Size (bytes)</th></tr>
								<tr><td>BMP</td><td>786554</td></tr>
								<tr><td>PNG</td><td>788485</td></tr>
								<tr><td>JPG</td><td>770446</td></tr>
							</table>
						</div>
					</section>
				</section>

				<section>
					<section>
						<h2>Solution: Fool the Human</h2>
						<p>Humans are very forgiving for loss of <em>some</em> quality</p>
						<table>
							<tr>
								<td><img class='fragment' src='./images/bison.jpg'></td>
								<td><img class='fragment' src='./images/khubilai-khan-portrait.jpg'></td>
							</tr>
						</table>
					</section>
					<section>
						<table>
							<tr>
								<td><img src='./images/girl-with-pearl-earings.jpg'></td>
								<td><img class='fragment' src='./images/evey-study.jpg'></td>
							</tr>
						</table>
					</section>

					<section data-background-video="./videos/cut.mp4,./videos/cut.webm">
						<div class='fragment translucent-black-background'>
							<p>
								<a href='https://youtu.be/Sp7HiqULakk'>https://youtu.be/Sp7HiqULakk</a>
							</p>
						</div>
					</section>
				</section>

				<section>
					<section data-background-video='./videos/visualization.mp4,./videos/visualization.webm'>
						<div class='translucent-black-background'>
							<h2>Let's Look At JPEG</h2>
						</div>
					</section>
					<section data-background='./images/2dsin.png'>
						<div class='translucent-black-background'>
							<h2>What Does JPEG Do?</h2>
							<ul>
								<li>
									Spatial to frequency conversion
									<ul>
										<li>similar to audio but for images, and instead of 1D, we use 2D</li>
									</ul>
								</li>
								<li class='fragment'>
									Fourier's Theorem
									<ul>
										<li><em>&ldquo;A wave is the sum of many sinusoidal waves.&rdquo;</em></li>
									</ul>
								</li>
								<li class='fragment'>DFT is often used to extract the sine waves of a wave (FFT for the fast variant)</li>
								<li class='fragment'>
									But we're going to use the DCT
									<ul>
										<li>
											Benefit over DFT
											<ul>
												<li class='fragment'>no complex numbers involved</li>
												<li class='fragment'>wave coefficient packed closer to lower frequencies</li>
											</ul>
										</li>
									</ul>
								</li>
							</ul>
						</div>
					</section>
					<section data-background='./images/2dsin.png'></section>

					<section data-background='./dct-example/grayscale-image.png'></section>
					<section data-background='./dct-example/split-image.png'></section>
					<section data-background='./dct-example/dct-split-image.png'>
						<div class='fragment translucent-black-background'>
							<table>
								<tr>
									<td>
										<p><img src='./dct-example/block-image.png' alt='pre-DCT'></p>
										<p>Before DCT</p>
									</td>
									<td>
										<p><img src='./dct-example/block-dct-image.png' alt='pre-DCT'></p>
										<p>After DCT</p>
									</td>
								</tr>
							</table>
						</div>
					</section>
					<section data-background='./dct-example/dct-split-image.png'>
						<div class='translucent-black-background'>
							<p>The block prior to the DCT: spatial domain. the block after: frequency domain</p>
							<p>N.B. The top-left pixel in the frequency domain is called DC, and the rest are called AC</p>
						</div>
					</section>
					<section data-background='./dct-example/dct-split-image.png'></section>
					<section data-background='./dct-example/dct-quantized-split-image.png'>
						<table class='fragment translucent-black-background'>
							<tr>
								<td>
									<p><img src='./dct-example/block-dct-image.png' alt='pre-DCT'></p>
									<p>Before Quantization</p>
								</td>
								<td>
									<p><img src='./dct-example/block-dct-quantized-image.png' alt='pre-DCT'></p>
									<p>After Quantization</p>
								</td>
							</tr>
						</table>
					</section>
					<section data-background='./dct-example/dct-quantized-split-image.png'>
						<h2>Run-Length-Encoding (RLE)</h2>
						<img src='./images/rle.png' alt='RLE'>
					</section>
					<section data-background='./dct-example/dct-quantized-image.png'>
						<div class='fragment'>
							<h2>We Send This</h2>
						</div>
					</section>
					<section data-background='./dct-example/dct-quantized-split-image.png'></section>
					<section data-background='./dct-example/idct-quantized-split-image.png'></section>
					<section data-background='./dct-example/idct-quantized-image.png'>
						<table class='fragment translucent-black-background'>
							<tr>
								<td>
									<p><img src='./dct-example/grayscale-image.png' alt='pre-DCT'></p>
									<p>Before Loss</p>
								</td>
								<td>
									<p><img src='./dct-example/idct-quantized-image.png' alt='pre-DCT'></p>
									<p>After Loss</p>
								</td>
							</tr>
						</table>
					</section>

					<section>
						<p>However, most modern encoders pretty much use a variation of JPEG</p>
					</section>
				</section>

				<section>
					<h2>A contender: Daala</h2>
				</section>

				<section>
					<section>
						<h2>Lapped Transform</h2>
						<p>Before we go ahead and use the DCT, we apply a pre-filter</p>
						<p class='fragment'><img src='./images/prefilter.png' alt='Prefilter'></p>
					</section>

					<section>
						<p>We then overlap the results of the pre-filter onto the DCT</p>
						<p><img src='./images/lapping.png' alt='Prefilter'></p>
					</section>

					<section>
						<p><img src='./images/lapped-transform-example.png' alt='Lapped Transform Example'></p>
					</section>

					<section>
						<p>Paper regarding the lapped transform</p>
						<p><a href="http://thanglong.ece.jhu.edu/Tran/Pub/prepost.pdf">http://thanglong.ece.jhu.edu/Tran/Pub/prepost.pdf</a></p>
					</section>
				</section>

				<section>

					<section>
						<h2>Gain-Shape Quantization</h2>
						<p>A type of vector quantization</p>
					</section>

					<section>
						<h2>Vector quantization</h2>
						<p>Instead of quantizing every scalar elements individually, group adjecent ones and quantize collectively</p>
					</section>

					<section>
						<table>
							<tr>
								<td><img src='./dct-example/grayscale-image.png' alt='Lena'></td>
								<td><img src='./images/tuples.png' alt='Lena'></td>
							</tr>
						</table>
					</section>

					<section>
						<img src='./images/naive-quantization.png' alt='Quantized Tuples'>
						<p class='fragment'>Problem: lost information + squandered range</p>
					</section>

					<section>
						<img src='./images/better-quantization.png' alt='Better quantized tuples'>
						<p class='fragment'>All quantized regions are used</p>
					</section>

					<section data-background='./images/sphere.png'>
						<h2>Gain-Shape Quantization</h2>
						<ul>
							<li>
								Given a block, <strong>we treat it like a vector</strong>
								<ul>
									<li>Let's call it <span class='math-katex'>\mathbf{v}</span></li>
								</ul>
							</li>
							<li>
								Given <span class='math-katex'>\mathbf{v}</span>, we get
								<ul>
									<li>The length (gain), which we will call <span class='math-katex'>g</span></li>
									<li>The direction (shape), which we will call <span class=math-katex>\mathbf{w}</span></li>
								</ul>
							</li>
							<li>We then quantize <span class='math-katex'>g</span> and <span class='math-katex'>\mathbf{w}</span></li>
						</ul>
					</section>
					<section data-background='./images/sphere.png'>
						<h2>Pyramid Vector Quantization</h2>
						<ul>
							<li>Instead of look-up tables, arithmetically group vectors</li>
							<li>Saves space</li>
						</ul>
					</section>
					<section data-background='./images/sphere.png'>
						<p>We have a function <span class='math-katex'>G</span> to derive <span class='math-katex'>G(g) = k</span>, <span class='math-katex'>k \in \mathbb{N}</span></p>
						<p>With <span class='math-katex'>k</span>, we get a <span class='math-katex'>W \subset \mathbb{Z}^N</span> such that <span class='math-katex'>\forall \mathbf{v} \in W (\sum\limits_{v}^{\mathbf{v}} |v| = k)</span></p>
						<p>
							We then have a function <span class='math-katex'>Q</span>, such that we can compute <span class='math-katex'>Q(\mathbf{w}|k) = \mathbf{q}</span>, <span class='math-katex'>\mathbf{q} \in W</span>
						</p>
					</section>

					<section>
						<p>Fischer, T.R. "A pyramid vector quantizer." <em>IEEE Transactions on Information Theory</em>. Issue 4 Volume 32 (1986): 568&mdash;583. Print.</p>
					</section>
				</section>

				<section>
					<section>
						<h2>Removing Pixels</h2>
						<p>Prediction</p>
					</section>
					<section>
						<p><img src='./images/predictor.png' alt='Prediction'></p>
					</section>
				</section>

				<section>
					<section>
						<h2>Let's Also Compress Colours!</h2>
						<ul class='fragment'>
							<li class='fragment'>Humans don't notice colours as much</li>
							<li class='fragment'>And even then, colours are 3D; you're practically sending the same image three times if you send RGB; better to distinguish chroma from luma</li>
							<li class='fragment'>Use YUV</li>
						</ul>
					</section>
					<section>
						<h2>Chroma From Luma Prediction</h2>
						<p>We compute a <span class='math-katex'>\alpha_u</span>, <span class='math-katex'>\alpha_v</span>, <span class='math-katex'>\beta_u</span><span class='math-katex'>\beta_v</span>, by performing a linear regression on the U and V channels</p>
						<p>We can then send <span class='math-katex'>\alpha_u</span>, <span class='math-katex'>\alpha_v</span>, <span class='math-katex'>\beta_u</span><span class='math-katex'>\beta_v</span>, and the decoder should be able to infer the final colour</p>
						<ul>
							<li><span class='math-katex'>DC_u = \alpha_u + \beta_uDC_y</span></li>
							<li><span class='math-katex'>AC_u[x, y] = \beta_uAC_Y[x, y]</span></li>
							<li><span class='math-katex'>DC_v = \alpha_v + \beta_vDC_y</span></li>
							<li><span class='math-katex'>AC_v[x, y] = \beta_vAC_Y[x, y]</span></li>
						</ul>
					</section>
				</section>

				<section>
					<section>
						<h2>Paint Deringing</h2>
						<ul class='fragment'>
							<li>Direction search</li>
							<li>Boundary pixel</li>
							<li>Painting</li>
						</ul>
					</section>
					<section>
						<p>Algorithm on finding the direction</p>
						<p><a href="http://jmvalin.ca/notes/intra_paint.pdf">http://jmvalin.ca/notes/intra_paint.pdf</a></p>
					</section>
					<section>
						<h2>Some Fun</h2>
					</section>
					<section data-background='./images/desert.jpg'></section>
					<section data-background='./images/desert-painted.jpg'></section>
					<section data-background='./images/horse.jpg'></section>
					<section data-background='./images/horse-painted.jpg'></section>
					<section data-background='./images/sydney.jpg'></section>
					<section data-background='./images/sydney-painted.jpg'></section>
					<section data-background-video='./videos/parkjoy.mp4,./videos/parkjoy.webm'></section>
					<section>
						<p>Enough fun; let's ask "to paint or not to paint"</p>
						<p class='fragment math-katex'>w = \min(1, \alpha\frac{Q^2}{12\sigma^2})</p>
						<ul class='fragment'>
							<li><span class='math-katex'>Q</span> is the quantization amount (quality)</li>
							<li><span class='math-katex'>\alpha</span> is a tunable value between <span>0</span> and <span>1</span></li>
							<li><span class='math-katex'>\sigma^2</span>is the mean squared distance between decoded image and painted image</li>
						</ul>
					</section>
				</section>

				<section>
					<p>The end-result</p>
					<a href="https://people.xiph.org/~xiphmont/demo/daala/update1-tool2b.shtml">https://people.xiph.org/~xiphmont/demo/daala/update1-tool2b.shtml</a>
				</section>

			</div>

		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>
		<script src='katex/katex.min.js'></script>

		<script>

			// Full list of configuration options available at:
			// https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				controls: true,
				progress: true,
				history: true,
				center: true,

				transition: 'slide', // none/fade/slide/convex/concave/zoom

				// Optional reveal.js plugins
				dependencies: [
					{ src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
					{ src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/highlight/highlight.js', async: true, condition: function() { return !!document.querySelector( 'pre code' ); }, callback: function() { hljs.initHighlightingOnLoad(); } },
					{ src: 'plugin/zoom-js/zoom.js', async: true },
					{ src: 'plugin/notes/notes.js', async: true }
				]
			});

		</script>

		<script>
			Array
				.prototype
				.slice
				.call(document.querySelectorAll('.math-katex'))
				.forEach(function (el) {
					// console.log();
					katex.render(el.innerHTML, el);
				});
		</script>

	</body>
</html>
